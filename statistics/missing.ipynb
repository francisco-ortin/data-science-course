{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/francisco-ortin/data-science-course/blob/main/statistics/missing.ipynb)\n",
    "[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2284eabc3cf7341d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Treating missing values\n",
    "\n",
    "In this notebook, you will have to treat missing values of a subset of the housing dataset.\n",
    "\n",
    "You must apply deletion and (single column) imputation/attribution to the dataset, so that it will no longer contain missing values."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "488488e8dda616c3"
  },
  {
   "cell_type": "code",
   "source": [
    "# make sure the numpy package is installed\n",
    "%pip install numpy --quiet\n",
    "repo='data-science-course'\n",
    "module='statistics'\n",
    "# if running in colab, install the required packages and copy the necessary files\n",
    "if get_ipython().__class__.__module__.startswith('google.colab'):\n",
    "    import os\n",
    "    if not os.path.exists(repo):\n",
    "        !git clone --filter=blob:none --sparse https://github.com/francisco-ortin/data-science-course.git  2>/dev/null\n",
    "        !cd {repo} && git sparse-checkout init --cone && git sparse-checkout set {module}  2>/dev/null\n",
    "    !cp --update {repo}/{module}/*.py . 2>/dev/null\n",
    "    !mkdir -p img data\n",
    "    !mv {repo}/{module}/img/* img/.  2>/dev/null\n",
    "    !mv {repo}/{module}/data/* data/.  2>/dev/null"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-03T17:40:41.743922Z",
     "start_time": "2025-11-03T17:40:40.273345Z"
    }
   },
   "id": "bd61bdc050939188",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the dataset\n",
    "\n",
    "Let's start by loading the dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c5e396bafa8e233"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('data/missing_housing.csv')\n",
    "number_of_instances = len(data)\n",
    "print(f'Total number of instances: {number_of_instances:,}.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-03T17:40:41.884962Z",
     "start_time": "2025-11-03T17:40:41.787252Z"
    }
   },
   "id": "86c2f7073563ce1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of instances: 20,818.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Showing the number of missing values per column\n",
    "\n",
    "Show the number of missing values per column in the dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57017ae832d07098"
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Number of missing values per column:\")\n",
    "columns_with_20_percent_missing_values = []\n",
    "columns_with_50_percent_missing_values = []\n",
    "columns_with_a_few_missing_values = []\n",
    "columns_with_no_missing_values = []\n",
    "for column in data.columns:\n",
    "    number_of_missing_instances = data[column].isnull().sum()\n",
    "    missing_values_percentage = number_of_missing_instances / number_of_instances * 100\n",
    "    print(f'\\t{column}: {number_of_instances:,}\\t\\t{number_of_missing_instances/number_of_instances*100:.2f}%')\n",
    "    if 20 <= missing_values_percentage < 50:\n",
    "        columns_with_20_percent_missing_values.append(column)\n",
    "    elif missing_values_percentage >= 50:\n",
    "        columns_with_50_percent_missing_values.append(column)\n",
    "    elif number_of_missing_instances > 0 and missing_values_percentage < 20:\n",
    "        columns_with_a_few_missing_values.append(column)\n",
    "    elif number_of_missing_instances == 0:\n",
    "        columns_with_no_missing_values.append(column)\n",
    "print(f'Columns with between 20% and 50% missing values: {columns_with_20_percent_missing_values}.')\n",
    "print(f'Columns with more than 50% missing values: {columns_with_50_percent_missing_values}.')\n",
    "print(f'Columns with missing values, less than 20%: {columns_with_a_few_missing_values}.')\n",
    "print(f'Columns with no missing values: {columns_with_no_missing_values}.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-03T17:40:42.293420Z",
     "start_time": "2025-11-03T17:40:42.258356Z"
    }
   },
   "id": "36649d31afbf7567",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values per column:\n",
      "\tId: 20,818\t\t0.00%\n",
      "\tSold Price: 20,818\t\t0.00%\n",
      "\tType: 20,818\t\t0.00%\n",
      "\tYear built: 20,818\t\t1.95%\n",
      "\tCooling: 20,818\t\t86.67%\n",
      "\tLot: 20,818\t\t87.48%\n",
      "\tBathrooms: 20,818\t\t7.25%\n",
      "\tTotal interior livable area: 20,818\t\t5.39%\n",
      "\tTotal spaces: 20,818\t\t1.66%\n",
      "\tRegion: 20,818\t\t0.01%\n",
      "\tParking features: 20,818\t\t9.75%\n",
      "\tAnnual tax amount: 20,818\t\t9.51%\n",
      "\tListed Price: 20,818\t\t0.00%\n",
      "\tLast Sold Price: 20,818\t\t38.71%\n",
      "\tCity: 20,818\t\t0.00%\n",
      "\tState: 20,818\t\t0.00%\n",
      "Columns with between 20% and 50% missing values: ['Last Sold Price'].\n",
      "Columns with more than 50% missing values: ['Cooling', 'Lot'].\n",
      "Columns with missing values, less than 20%: ['Year built', 'Bathrooms', 'Total interior livable area', 'Total spaces', 'Region', 'Parking features', 'Annual tax amount'].\n",
      "Columns with no missing values: ['Id', 'Sold Price', 'Type', 'Listed Price', 'City', 'State'].\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deletion\n",
    "\n",
    "Delete the missing values you think deletion is the most appropriate method. Justify your choices."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90141bdc92c3373f"
  },
  {
   "cell_type": "code",
   "source": [
    "# write your code here\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-03T17:40:42.320110Z",
     "start_time": "2025-11-03T17:40:42.313107Z"
    }
   },
   "id": "1384a02a655960d2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single-column imputation/attribution\n",
    "\n",
    "Analyze all the columns with missing values and decide which imputation/attribution method is more appropriate for each one of them. Then, apply the chosen method to the dataset. Do it *only* for single column imputation/attribution. For multiple column imputation/attribution, just include them in the cell at the end of the notebook (you do not need to implement it)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "449e28620cc29cf4"
  },
  {
   "cell_type": "code",
   "source": [
    "# write your code here\n",
    "\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-03T17:40:42.384628Z",
     "start_time": "2025-11-03T17:40:42.375887Z"
    }
   },
   "id": "c2717e402cc2345c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "29d17ca641e465b9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multiple-column imputation/attribution\n",
    "\n",
    "Write below a list of columns that you think must be used a method that requires multiple columns for the imputation. Include, for each column, an indication of the columns you think are required for the imputation. Indicate if it is a regression or classification imputation. Justify your choices. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a9e1ecc3991047c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Write your answer here*\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2b875e4f31eed69"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
